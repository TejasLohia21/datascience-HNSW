{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import hnswlib\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from heapq import heappush, heappop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to your GloVe file (update this based on your downloaded version)\n",
    "glove_path = \"/Users/tejasmacipad/Desktop/Projects/DataScience/datascience-HNSW/glove/glove.6B.100d.txt\"\n",
    "\n",
    "# Load GloVe vectors\n",
    "word_to_vec = {}\n",
    "words = []\n",
    "vectors = []\n",
    "\n",
    "with open(glove_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]  # First token is the word\n",
    "        vector = np.array(values[1:], dtype=np.float32)  # Rest are vector values\n",
    "        word_to_vec[word] = vector\n",
    "        words.append(word)\n",
    "        vectors.append(vector)\n",
    "\n",
    "# Convert to numpy array\n",
    "vectors = np.array(vectors, dtype=np.float32)\n",
    "print(f\"Loaded {len(words)} word vectors of dimension {vectors.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = vectors.shape[1]  # Embedding dimension\n",
    "num_elements = len(words)  # Number of words\n",
    "\n",
    "# Initialize HNSW index\n",
    "hnsw_index = hnswlib.Index(space=\"l2\", dim=dim)  # \"l2\" is Euclidean distance\n",
    "\n",
    "# Set up the index\n",
    "hnsw_index.init_index(max_elements=num_elements, ef_construction=200, M=16)\n",
    "\n",
    "# Add word vectors to the index\n",
    "hnsw_index.add_items(vectors)\n",
    "\n",
    "print(\"HNSW index built successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = vectors.shape[1]  # Embedding dimension\n",
    "num_elements = len(words)  # Number of words\n",
    "\n",
    "# Initialize HNSW index\n",
    "hnsw_index = hnswlib.Index(space=\"l2\", dim=dim)  # \"l2\" is Euclidean distance\n",
    "\n",
    "# Set up the index\n",
    "hnsw_index.init_index(max_elements=num_elements, ef_construction=200, M=16)\n",
    "\n",
    "# Add word vectors to the index\n",
    "hnsw_index.add_items(vectors)\n",
    "\n",
    "print(\"HNSW index built successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Query\n",
    "find_similar_words(\"king\", k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Query\n",
    "find_similar_words(\"king\", k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_similar_words_cosine(query_word, k=6):\n",
    "    if query_word not in word_to_vec:\n",
    "        return f\"'{query_word}' not found in vocabulary!\"\n",
    "\n",
    "    query_vector = word_to_vec[query_word].reshape(1, -1)\n",
    "    labels, distances = hnsw_index_cosine.knn_query(query_vector, k=k)\n",
    "\n",
    "    print(f\"\\nTop {k} words similar to '{query_word}':\")\n",
    "    for i, index in enumerate(labels[0]):\n",
    "        print(f\"{i+1}. {words[index]} (Distance: {distances[0][i]:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for a in range(1):\n",
    "    find_similar_words_cosine(\"king\", k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Generate 10^5 random query indices\n",
    "num_queries = 10**5\n",
    "query_indices = np.random.randint(0, len(words), size=num_queries)\n",
    "\n",
    "# Step 2: Get the corresponding query vectors\n",
    "query_vectors = vectors[query_indices]\n",
    "\n",
    "# Step 3: Use NearestNeighbors to find 100 nearest neighbors\n",
    "k = 100\n",
    "nn = NearestNeighbors(n_neighbors=k, algorithm='auto', metric='l2')\n",
    "nn.fit(vectors)\n",
    "\n",
    "# Step 4: For each query, get the indices of the 100 nearest neighbors\n",
    "distances, neighbor_indices = nn.kneighbors(query_vectors)\n",
    "\n",
    "# Step 5: Store results in a dictionary {query_word: [neighbor_words]}\n",
    "query_to_neighbors = {}\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Step 5: Store results in a dictionary {query_word: [neighbor_words]}\n",
    "query_to_neighbors = {}\n",
    "for i in tqdm(range(len(query_indices)), desc=\"Finding nearest neighbors\"):\n",
    "    query_idx = query_indices[i]\n",
    "    query_word = words[query_idx]\n",
    "    neighbor_words = [words[idx] for idx in neighbor_indices[i]]\n",
    "    query_to_neighbors[query_word] = neighbor_words\n",
    "\n",
    "print(f\"Stored nearest neighbors for {len(query_to_neighbors)} queries.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open(\"query_neighbors.json\", \"w\") as f:\n",
    "    json.dump(query_to_neighbors, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Load the saved query-to-neighbors mapping\n",
    "with open(\"query_neighbors.json\", \"r\") as f:\n",
    "    query_to_neighbors = json.load(f)\n",
    "\n",
    "print(f\"Loaded {len(query_to_neighbors)} queries from file.\")\n",
    "\n",
    "# Step 6: Create a dictionary mapping each unique query_word to its vector\n",
    "query_word_vectors = {word: word_to_vec[word] for word in query_to_neighbors}\n",
    "\n",
    "print(f\"Stored vectors for {len(query_word_vectors)} unique query words.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_to_neighbors_vectors = {}\n",
    "\n",
    "for i in tqdm(range(len(query_indices)), desc=\"Finding nearest neighbors\"):\n",
    "    query_idx = query_indices[i]\n",
    "    neighbor_indices_list = neighbor_indices[i]\n",
    "    query_to_neighbors_vectors[query_idx] = neighbor_indices_list  # All indices, not vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# Flatten all neighbor indices into a single list\n",
    "all_neighbors = [idx for neighbors in query_to_neighbors_vectors.values() for idx in neighbors]\n",
    "\n",
    "# Count frequency of each neighbor index\n",
    "freq_counter = Counter(all_neighbors)\n",
    "\n",
    "# Create DataFrame and sort\n",
    "freq_df = pd.DataFrame(freq_counter.items(), columns=[\"Index\", \"Frequency\"]).sort_values(\"Frequency\", ascending=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(all_neighbors))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(freq_df.head())  # Preview\n",
    "print(freq_df.tail())  # Preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#printing the average\n",
    "average = freq_df[\"Frequency\"].mean()\n",
    "print(f\"Average frequency of neighbors: {average}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(freq_df))  # Total unique neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(freq_df))  # Total unique neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import squarify  # pip install squarify if not already installed\n",
    "import numpy as np\n",
    "\n",
    "# Select top N most frequent indices\n",
    "top_n = 30\n",
    "freq_top = freq_df.head(top_n)\n",
    "\n",
    "# 1. Horizontal Bar Chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(freq_top[\"Index\"].astype(str), freq_top[\"Frequency\"], color='skyblue')\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Index\")\n",
    "plt.title(f\"Top {top_n} Most Frequent Neighbor Indices\")\n",
    "plt.gca().invert_yaxis()  # Highest freq on top\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Cumulative Frequency Line Plot\n",
    "freq_df_sorted = freq_df.sort_values(\"Frequency\", ascending=False)\n",
    "cum_freq = np.cumsum(freq_df_sorted[\"Frequency\"])\n",
    "cum_freq = cum_freq / cum_freq.max()  # Normalize to 0â€“1\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(range(len(cum_freq)), cum_freq, marker='o', linestyle='-', color='green')\n",
    "plt.title(\"Cumulative Frequency of Neighbor Indices\")\n",
    "plt.xlabel(\"Index Rank\")\n",
    "plt.ylabel(\"Cumulative Frequency (Normalized)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import squarify  # pip install squarify if not already installed\n",
    "import numpy as np\n",
    "\n",
    "# Select top N most frequent indices\n",
    "top_n = 30\n",
    "freq_top = freq_df.head(top_n)\n",
    "\n",
    "# 1. Horizontal Bar Chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(freq_top[\"Index\"].astype(str), freq_top[\"Frequency\"], color='skyblue')\n",
    "plt.xlabel(\"Frequency\")\n",
    "plt.ylabel(\"Index\")\n",
    "plt.title(f\"Top {top_n} Most Frequent Neighbor Indices\")\n",
    "plt.gca().invert_yaxis()  # Highest freq on top\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 3. Cumulative Frequency Line Plot\n",
    "freq_df_sorted = freq_df.sort_values(\"Frequency\", ascending=False)\n",
    "cum_freq = np.cumsum(freq_df_sorted[\"Frequency\"])\n",
    "cum_freq = cum_freq / cum_freq.max()  # Normalize to 0â€“1\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(range(len(cum_freq)), cum_freq, marker='o', linestyle='-', color='green')\n",
    "plt.title(\"Cumulative Frequency of Neighbor Indices\")\n",
    "plt.xlabel(\"Index Rank\")\n",
    "plt.ylabel(\"Cumulative Frequency (Normalized)\")\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
